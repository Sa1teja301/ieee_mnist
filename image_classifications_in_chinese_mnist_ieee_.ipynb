{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade\n",
        "import opendatasets as od\n",
        "dataset_url = 'https://www.kaggle.com/datasets/gpreda/chinese-mnist'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtVtiPK4ollj",
        "outputId": "7edc5612-2edd-45e1-8ba9-d60096a98e27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: rushiky\n",
            "Your Kaggle Key: ··········\n",
            "Downloading chinese-mnist.zip to ./chinese-mnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16.5M/16.5M [00:02<00:00, 8.01MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "id": "YtVtiPK4ollj"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e916e9ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:29:49.026764Z",
          "iopub.status.busy": "2021-11-07T10:29:49.025986Z",
          "iopub.status.idle": "2021-11-07T10:29:57.919696Z",
          "shell.execute_reply": "2021-11-07T10:29:57.920303Z"
        },
        "papermill": {
          "duration": 8.918077,
          "end_time": "2021-11-07T10:29:57.920650",
          "exception": false,
          "start_time": "2021-11-07T10:29:49.002573",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e916e9ad",
        "outputId": "1119f94f-77fd-4f72-ffee-a0b8f3ec1556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b8fef70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:29:57.951953Z",
          "iopub.status.busy": "2021-11-07T10:29:57.951177Z",
          "iopub.status.idle": "2021-11-07T10:30:00.374283Z",
          "shell.execute_reply": "2021-11-07T10:30:00.373780Z"
        },
        "papermill": {
          "duration": 2.440621,
          "end_time": "2021-11-07T10:30:00.374419",
          "exception": false,
          "start_time": "2021-11-07T10:29:57.933798",
          "status": "completed"
        },
        "tags": [],
        "id": "2b8fef70"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "\n",
        "import cv2\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score as a_s\n",
        "import os \n",
        "from torchsummary import summary\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "625ca6aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:00.402869Z",
          "iopub.status.busy": "2021-11-07T10:30:00.402323Z",
          "iopub.status.idle": "2021-11-07T10:30:00.431727Z",
          "shell.execute_reply": "2021-11-07T10:30:00.431263Z",
          "shell.execute_reply.started": "2021-11-07T10:06:57.621920Z"
        },
        "papermill": {
          "duration": 0.045384,
          "end_time": "2021-11-07T10:30:00.431846",
          "exception": false,
          "start_time": "2021-11-07T10:30:00.386462",
          "status": "completed"
        },
        "tags": [],
        "id": "625ca6aa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('chinese-mnist/chinese_mnist.csv',sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "967bfae9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:00.460321Z",
          "iopub.status.busy": "2021-11-07T10:30:00.459471Z",
          "iopub.status.idle": "2021-11-07T10:30:00.485004Z",
          "shell.execute_reply": "2021-11-07T10:30:00.485455Z",
          "shell.execute_reply.started": "2021-11-07T10:07:01.431761Z"
        },
        "papermill": {
          "duration": 0.041617,
          "end_time": "2021-11-07T10:30:00.485624",
          "exception": false,
          "start_time": "2021-11-07T10:30:00.444007",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "967bfae9",
        "outputId": "919bdbdb-06df-477d-8e8d-09790f78af05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   suite_id   15000 non-null  int64 \n",
            " 1   sample_id  15000 non-null  int64 \n",
            " 2   code       15000 non-null  int64 \n",
            " 3   value      15000 non-null  int64 \n",
            " 4   character  15000 non-null  object\n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 586.1+ KB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df.isnull().sum(),df.shape \n",
        "df.info()\n",
        "X = df.drop('character', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fe1e2600",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:00.520758Z",
          "iopub.status.busy": "2021-11-07T10:30:00.518637Z",
          "iopub.status.idle": "2021-11-07T10:30:00.523496Z",
          "shell.execute_reply": "2021-11-07T10:30:00.523015Z",
          "shell.execute_reply.started": "2021-11-07T10:08:21.148426Z"
        },
        "papermill": {
          "duration": 0.025076,
          "end_time": "2021-11-07T10:30:00.523641",
          "exception": false,
          "start_time": "2021-11-07T10:30:00.498565",
          "status": "completed"
        },
        "tags": [],
        "id": "fe1e2600"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, k,l, csv_file ='chinese-mnist/chinese_mnist.csv'):\n",
        "\n",
        "\n",
        "    self.df = pd.read_csv(csv_file)\n",
        "    \n",
        "\n",
        "    self.k= {'九':int(9),'十':int(10),'百':int(11),'千':int(12),'万':int(13),'亿':int(14),'零':int(0),'一':int(1),'二':int(2),'三':int(3),'四':int(4),'五':int(5),'六':int(6),'七':int(7),'八':int(8)}\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    self.target = 'character'\n",
        "    self.features = ['suite_id','sample_id','code',]\n",
        "\n",
        "\n",
        "    self.labels   = np.asarray(self.df.iloc[:, 4])\n",
        "    \n",
        "    self.y = df[self.target]\n",
        "    self.X = df.drop(self.target, axis =1 )\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    single_image_label = self.labels[idx]\n",
        "\n",
        "    class_id = self.k[single_image_label]\n",
        "    \n",
        "    img = Image.open(f\"chinese-mnist/data/data/input_{self.X.iloc[idx, 0]}_{self.X.iloc[idx, 1]}_{self.X.iloc[idx, 2]}.jpg\")\n",
        "    img = np.array(img) # convert to np.array\n",
        "       \n",
        "\n",
        "    return img, class_id\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c1cf822b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:00.555638Z",
          "iopub.status.busy": "2021-11-07T10:30:00.553499Z",
          "iopub.status.idle": "2021-11-07T10:30:00.614160Z",
          "shell.execute_reply": "2021-11-07T10:30:00.613700Z",
          "shell.execute_reply.started": "2021-11-07T10:08:23.564078Z"
        },
        "papermill": {
          "duration": 0.078702,
          "end_time": "2021-11-07T10:30:00.614269",
          "exception": false,
          "start_time": "2021-11-07T10:30:00.535567",
          "status": "completed"
        },
        "tags": [],
        "id": "c1cf822b"
      },
      "outputs": [],
      "source": [
        "train_df = df.groupby('value').apply(lambda x: x.sample(700, random_state=42)).reset_index(drop=True)\n",
        "x_train, y_train  = train_df.iloc[:, :-2], train_df.iloc[:, -2]\n",
        "\n",
        "test_df  = df.groupby('value').apply(lambda x: x.sample(300, random_state=42)).reset_index(drop=True)\n",
        "x_test, y_test    = test_df.iloc[:, :-2], test_df.iloc[:, -2]\n",
        " \n",
        "train_ds = CustomDataset(x_train, y_train)\n",
        "trainloader = DataLoader(dataset=train_ds,batch_size=32, shuffle=True)\n",
        "\n",
        "test_ds = CustomDataset(x_test, y_test)\n",
        "testloader = DataLoader(test_ds, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a9e88a96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:01.098912Z",
          "iopub.status.busy": "2021-11-07T10:30:01.097484Z",
          "iopub.status.idle": "2021-11-07T10:30:01.147189Z",
          "shell.execute_reply": "2021-11-07T10:30:01.146763Z",
          "shell.execute_reply.started": "2021-11-07T10:08:31.299965Z"
        },
        "papermill": {
          "duration": 0.070299,
          "end_time": "2021-11-07T10:30:01.147299",
          "exception": false,
          "start_time": "2021-11-07T10:30:01.077000",
          "status": "completed"
        },
        "tags": [],
        "id": "a9e88a96"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(64*13*13, 500)\n",
        "        self.fc2 = nn.Linear(500, 15)\n",
        "\n",
        "        self.log_softmax = nn.LogSoftmax(dim=0)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        output = self.log_softmax(x)\n",
        "        return output\n",
        "\n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "26702731",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:01.178943Z",
          "iopub.status.busy": "2021-11-07T10:30:01.178210Z",
          "iopub.status.idle": "2021-11-07T10:30:01.180303Z",
          "shell.execute_reply": "2021-11-07T10:30:01.180758Z",
          "shell.execute_reply.started": "2021-11-07T10:08:34.300648Z"
        },
        "papermill": {
          "duration": 0.020119,
          "end_time": "2021-11-07T10:30:01.180882",
          "exception": false,
          "start_time": "2021-11-07T10:30:01.160763",
          "status": "completed"
        },
        "tags": [],
        "id": "26702731"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "los = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001,)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbe6a66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:30:01.210310Z",
          "iopub.status.busy": "2021-11-07T10:30:01.209487Z",
          "iopub.status.idle": "2021-11-07T10:38:38.683144Z",
          "shell.execute_reply": "2021-11-07T10:38:38.682553Z",
          "shell.execute_reply.started": "2021-11-07T10:08:36.538900Z"
        },
        "papermill": {
          "duration": 517.488859,
          "end_time": "2021-11-07T10:38:38.683291",
          "exception": false,
          "start_time": "2021-11-07T10:30:01.194432",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dbe6a66",
        "outputId": "58c608af-70e0-4f6b-b194-71d40e36f527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5\n",
            "\tIteration: 0\t Loss: 0.008\n",
            "\tIteration: 96\t Loss: 0.441\n",
            "\tIteration: 192\t Loss: 0.267\n",
            "\tIteration: 288\t Loss: 0.203\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "print_every = 96\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "\n",
        "        \n",
        "        images = images.resize_(images.size()[0], 64,64).float()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(images)   \n",
        "        losss = los(output, labels)     \n",
        "        losss.backward()                 \n",
        "        optimizer.step()                 \n",
        "        \n",
        "        running_loss += losss.item()\n",
        "        \n",
        "        if i % print_every == 0:\n",
        "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/len(trainloader):.3f}\")\n",
        "            running_loss = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ac24a2ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-11-07T10:38:38.735466Z",
          "iopub.status.busy": "2021-11-07T10:38:38.734613Z",
          "iopub.status.idle": "2021-11-07T10:39:16.821626Z",
          "shell.execute_reply": "2021-11-07T10:39:16.822267Z",
          "shell.execute_reply.started": "2021-11-07T10:19:26.506824Z"
        },
        "papermill": {
          "duration": 38.116751,
          "end_time": "2021-11-07T10:39:16.822473",
          "exception": false,
          "start_time": "2021-11-07T10:38:38.705722",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac24a2ad",
        "outputId": "3b7a93f6-f945-47d9-dd99-4b641175d44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results with respect to confusion matrix: \n",
            "[[977   0   0   2   2   4   2   1   3   0   0   3   3   2   1]\n",
            " [  0 991   3   0   0   0   1   0   0   1   0   2   0   2   0]\n",
            " [  1  13 968  15   1   0   1   1   0   0   0   0   0   0   0]\n",
            " [  1   1  95 886   0  12   1   0   1   0   0   0   1   1   1]\n",
            " [  7   2   1   0 961   0   1   1  11   1   3  11   0   0   1]\n",
            " [  3   0   2  33   1 943   1   0   1   3   0   7   2   0   4]\n",
            " [ 10   4   8   6   3   4 927   1  15   4   5   3   4   5   1]\n",
            " [  3   1   0   4   2   2   0 963   3   9   2   3   2   0   6]\n",
            " [  0   1   0   0   0   0   3   0 994   1   0   1   0   0   0]\n",
            " [  2   0   2   1   8   8  10  11  13 915   3   2   2   2  21]\n",
            " [  0   4   0   0   2   4   2   2  10   4 956   0  15   1   0]\n",
            " [  5   2   4   1  19  12   0   2   4   4   0 930   3  10   4]\n",
            " [  8   1   5   5   1   2  10   1   7   0  27   6 923   3   1]\n",
            " [  4   1   1   1   3   4   2   0   2   1   1  10   1 968   1]\n",
            " [  3   1   2   2   8   9   2   2  15  20   1   4   1   2 928]] \n",
            "and the accuracy score is : \n",
            " 0.9486666666666667\n"
          ]
        }
      ],
      "source": [
        "test_size = len(test_ds)\n",
        "train_size = len(train_ds)\n",
        "r_labels = np.array([])\n",
        "preds  = np.array([])\n",
        "\n",
        "correct_preds = np.array([])\n",
        "\n",
        "\n",
        "for i, (images, labels) in enumerate(iter(testloader)):\n",
        "  model.eval()\n",
        "\n",
        "    \n",
        "  images = images.resize_(images.size()[0], 64,64).float()\n",
        "\n",
        "  outputs = model(images)\n",
        "\n",
        "  loss = los(outputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "  r_labels = np.concatenate((r_labels, labels.numpy()))\n",
        "\n",
        "\n",
        "  for index, item in enumerate(outputs):\n",
        "      if r_labels[index] == torch.argmax(item):\n",
        "          correct_preds += 1\n",
        "\n",
        "      preds  = np.concatenate((preds, torch.argmax(item).unsqueeze(-1).detach().numpy()))\n",
        "\n",
        "\n",
        "conf_mat = confusion_matrix(r_labels, preds)\n",
        "\n",
        "\n",
        "accuracy_scores= a_s(r_labels, preds)\n",
        "\n",
        "print(f'Test results with respect to confusion matrix: \\n{conf_mat} \\nand the accuracy score is : \\n {accuracy_scores}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0LB0K7b7tgr"
      },
      "id": "K0LB0K7b7tgr",
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 612.866795,
      "end_time": "2021-11-07T10:39:54.603115",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-11-07T10:29:41.736320",
      "version": "2.3.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}